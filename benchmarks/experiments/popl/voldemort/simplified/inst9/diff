Parsing files...
Merge Instance for method (Ident "PerformSerialPutRequests",Ident "execute",[RefType (ClassRefType (ClassType [(Ident "Pipeline",[])]))])
public void execute (Pipeline pipeline)
{
  int currentNode = 0;
  List<Node> nodes = pipelineData.getNodes();
  if (logger.isDebugEnabled())
    logger.debug("Performing serial put requests to determine master");
  for (; currentNode < nodes.size() ; currentNode++)
  {
    Node node = nodes.get(currentNode);
    pipelineData.incrementNodeIndex();
    VectorClock versionedClock = (VectorClock) versioned.getVersion();
    final Versioned<byte[]> versionedCopy = new Versioned<byte[]>(versioned.getValue(), versionedClock.incremented(node.getId(), time.getMilliseconds()));
    if (logger.isTraceEnabled())
      logger.trace(("Attempt #" + currentNode + 1 + " to perform put (node " + node.getId() + ")"));
    long start = System.nanoTime();
    <?HOLE?>
  }
  if (pipelineData.getSuccesses() < 1)
  {
    List<Exception> failures = pipelineData.getFailures();
    pipelineData.setFatalError(new InsufficientOperationalNodesException("No master node succeeded!", (failures.size() > 0 ? failures.get(0) : null)));
    <?HOLE?>
    return;
  }
  currentNode++;
  if (currentNode == nodes.size())
  {
    if (pipelineData.getSuccesses() < required)
    {
      pipelineData.setFatalError(new InsufficientOperationalNodesException((required + " " + pipeline.getOperation().getSimpleName() + "s required, but only " + pipelineData.getSuccesses() + " succeeded"), pipelineData.getFailures()));
      <?HOLE?>
    }
    else
    {
      if (pipelineData.getZonesRequired() != null)
      {
        int zonesSatisfied = pipelineData.getZoneResponses().size();
        if (zonesSatisfied >= pipelineData.getZonesRequired() + 1)
        {
          pipeline.addEvent(completeEvent);
        }
        else
        {
          pipelineData.setFatalError(new InsufficientZoneResponsesException((pipelineData.getZonesRequired() + 1 + " " + pipeline.getOperation().getSimpleName() + "s required zone, but only " + zonesSatisfied + " succeeded")));
          <?HOLE?>
        }
      }
      else
      {
        pipeline.addEvent(completeEvent);
      }
    }
  }
  else
  {
    pipeline.addEvent(masterDeterminedEvent);
  }
}
Edit Base:
Hole 1:
[SLoop]: try
{
  stores.get(node.getId()).put(key, versionedCopy);
  long requestTime = (System.nanoTime() - start) / Time.NS_PER_MS;
  pipelineData.incrementSuccesses();
  failureDetector.recordSuccess(node, requestTime);
  if (logger.isTraceEnabled())
    logger.trace(("Put on node " + node.getId() + " succeeded, using as master"));
  pipelineData.setMaster(node);
  pipelineData.setVersionedCopy(versionedCopy);
  pipelineData.getZoneResponses().add(node.getZoneId());
  break;
}
catch (Exception e)
{
  long requestTime = (System.nanoTime() - start) / Time.NS_PER_MS;
  if (handleResponseError(e, node, requestTime, pipeline, failureDetector))
    return;
}
Hole 2:
[SCond]: pipeline.addEvent(Event.ERROR);
Hole 3:
[SCond,SCond]: pipeline.addEvent(Event.ERROR);
Hole 4:
[SCond,SCond,SCond,SCond]: pipeline.addEvent(Event.ERROR);

Edit A:
Hole 1:
[SLoop]: try
{
  stores.get(node.getId()).put(key, versionedCopy, transforms);
  long requestTime = (System.nanoTime() - start) / Time.NS_PER_MS;
  pipelineData.incrementSuccesses();
  failureDetector.recordSuccess(node, requestTime);
  if (logger.isTraceEnabled())
    logger.trace(("Put on node " + node.getId() + " succeeded, using as master"));
  pipelineData.setMaster(node);
  pipelineData.setVersionedCopy(versionedCopy);
  pipelineData.getZoneResponses().add(node.getZoneId());
  break;
}
catch (Exception e)
{
  long requestTime = (System.nanoTime() - start) / Time.NS_PER_MS;
  if (handleResponseError(e, node, requestTime, pipeline, failureDetector))
    return;
}
Hole 2:
[SCond]: pipeline.addEvent(Event.ERROR);
Hole 3:
[SCond,SCond]: pipeline.addEvent(Event.ERROR);
Hole 4:
[SCond,SCond,SCond,SCond]: pipeline.addEvent(Event.ERROR);

Edit B:
Hole 1:
[SLoop]: try
{
  stores.get(node.getId()).put(key, versionedCopy);
  long requestTime = (System.nanoTime() - start) / Time.NS_PER_MS;
  pipelineData.incrementSuccesses();
  failureDetector.recordSuccess(node, requestTime);
  if (logger.isTraceEnabled())
    logger.trace(("Put on node " + node.getId() + " succeeded, using as master"));
  pipelineData.setMaster(node);
  pipelineData.setVersionedCopy(versionedCopy);
  pipelineData.getZoneResponses().add(node.getZoneId());
  break;
}
catch (Exception e)
{
  long requestTime = (System.nanoTime() - start) / Time.NS_PER_MS;
  if (handleResponseError(e, node, requestTime, pipeline, failureDetector))
    return;
}
Hole 2:
[SCond]: pipeline.abort();
Hole 3:
[SCond,SCond]: pipeline.abort();
Hole 4:
[SCond,SCond,SCond,SCond]: pipeline.abort();

Edit M:
Hole 1:
[SLoop]: try
{
  stores.get(node.getId()).put(key, versionedCopy, transforms);
  long requestTime = (System.nanoTime() - start) / Time.NS_PER_MS;
  pipelineData.incrementSuccesses();
  failureDetector.recordSuccess(node, requestTime);
  if (logger.isTraceEnabled())
    logger.trace(("Put on node " + node.getId() + " succeeded, using as master"));
  pipelineData.setMaster(node);
  pipelineData.setVersionedCopy(versionedCopy);
  pipelineData.getZoneResponses().add(node.getZoneId());
  break;
}
catch (Exception e)
{
  long requestTime = (System.nanoTime() - start) / Time.NS_PER_MS;
  if (handleResponseError(e, node, requestTime, pipeline, failureDetector))
    return;
}
Hole 2:
[SCond]: pipeline.abort();
Hole 3:
[SCond,SCond]: pipeline.abort();
Hole 4:
[SCond,SCond,SCond,SCond]: pipeline.abort();


